{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load the Netflix dataset and do some basic cleaning of the title column by removing extra spaces and changing all the letters to lowercase. This will help avoid issues when checking for duplicate titles later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"netflix1.csv\")\n",
    "\n",
    "df['title'] = df['title'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we clean the movie titles by standardizing case and removing leading/trailing spaces. We then identify and count duplicate titles and display the rows containing those duplicates along with relevant metadata (title, director, and country)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles with duplicates:\n",
      " title_clean\n",
      "esperando la carroza        2\n",
      "9-feb                       2\n",
      "fullmetal alchemist         2\n",
      "consequences                2\n",
      "15-aug                      2\n",
      "death note                  2\n",
      "sin senos sí hay paraíso    2\n",
      "love in a puff              2\n",
      "22-jul                      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Full rows with duplicate titles:\n",
      "                          title            director        country\n",
      "220             love in a puff      Pang Ho-cheung      Hong Kong\n",
      "393                      9-feb           Not Given       Pakistan\n",
      "415       esperando la carroza     Alejandro Doria      Argentina\n",
      "537                      9-feb           Not Given       Pakistan\n",
      "2590              consequences        Ozan Açıktan         Turkey\n",
      "2925                    15-aug  Swapnaneel Jayakar          India\n",
      "3285                    22-jul     Paul Greengrass         Norway\n",
      "3637       fullmetal alchemist       Fumihiko Sori          Japan\n",
      "3819                death note        Adam Wingard  United States\n",
      "4260                    22-jul     Paul Greengrass         Norway\n",
      "4261                    15-aug  Swapnaneel Jayakar          India\n",
      "4718              consequences        Ozan Açıktan         Turkey\n",
      "4856      esperando la carroza     Alejandro Doria      Argentina\n",
      "5361            love in a puff      Pang Ho-cheung      Hong Kong\n",
      "6854  sin senos sí hay paraíso           Not Given  United States\n",
      "8061       fullmetal alchemist           Not Given          Japan\n",
      "8260                death note           Not Given          Japan\n",
      "8667  sin senos sí hay paraíso           Not Given  United States\n"
     ]
    }
   ],
   "source": [
    "df['title_clean'] = df['title'].str.strip().str.lower()\n",
    "title_counts = df['title_clean'].value_counts()\n",
    "duplicates = title_counts[title_counts > 1]\n",
    "print(\"Titles with duplicates:\\n\", duplicates)\n",
    "\n",
    "duplicate_rows = df[df['title_clean'].isin(duplicates.index)]\n",
    "print(\"\\nFull rows with duplicate titles:\\n\", duplicate_rows[['title', 'director', 'country']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will clean and standardize the `date_added` column. First, we will convert it into proper date format, and then change it to a more readable style like dd-mm-yyyy. This will help make the date values easier to understand and use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               title  date_added\n",
      "0               dick johnson is dead  25-09-2021\n",
      "1                          ganglands  24-09-2021\n",
      "2                      midnight mass  24-09-2021\n",
      "3   confessions of an invisible girl  22-09-2021\n",
      "4                            sankofa  24-09-2021\n",
      "5      the great british baking show  24-09-2021\n",
      "6                       the starling  24-09-2021\n",
      "7    motu patlu in the game of zones  01-05-2021\n",
      "8                       je suis karl  23-09-2021\n",
      "9           motu patlu in wonderland  01-05-2021\n",
      "10    motu patlu: deep sea adventure  01-05-2021\n",
      "11          motu patlu: mission moon  01-05-2021\n",
      "12                  99 songs (tamil)  21-05-2021\n",
      "13       bridgerton - the afterparty  13-07-2021\n",
      "14     bling empire - the afterparty  12-06-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l3/6_1d03v13r3423dpvq4sswyw0000gn/T/ipykernel_2390/3149749445.py:2: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['date_added'] = pd.to_datetime(df['date_added'], dayfirst=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "df['date_added'] = pd.to_datetime(df['date_added'], dayfirst=True, errors='coerce')\n",
    "\n",
    "df['date_added'] = df['date_added'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "print(df[['title', 'date_added']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will extract the year from the `date_added` column. First, we’ll make sure the date is in the correct format, and then we’ll create a new column called `year_added` that stores just the year part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_added'] = pd.to_datetime(df['date_added'], format='%d-%m-%Y', errors='coerce')\n",
    "df['year_added'] = df['date_added'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will clean the `duration` column. We'll separate the numbers and the text (like minutes or seasons) into two new columns: `duration_int` and `duration_type`. Then we’ll convert the numeric part to float so that it can be used for analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_int</th>\n",
       "      <th>duration_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90 min</td>\n",
       "      <td>90.0</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Season</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Season</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91 min</td>\n",
       "      <td>91.0</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125 min</td>\n",
       "      <td>125.0</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  duration_int duration_type\n",
       "0    90 min          90.0           min\n",
       "1  1 Season           1.0        Season\n",
       "2  1 Season           1.0        Season\n",
       "3    91 min          91.0           min\n",
       "4   125 min         125.0           min"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['duration_int', 'duration_type']] = df['duration'].str.extract(r'(\\d+)\\s*(\\w+)')\n",
    "df['duration_int'] = df['duration_int'].astype('float')  \n",
    "df[['duration', 'duration_int', 'duration_type']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'title_clean' if no longer needed\n",
    "df.drop(columns=['title_clean'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will clean the `title` column by removing extra spaces and converting everything to lowercase. Then, we’ll remove any duplicate titles to keep only unique ones. Finally, we’ll check the new dataset shape and export the cleaned data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape after duplicate removal: (8781, 13)\n"
     ]
    }
   ],
   "source": [
    "df['title'] = df['title'].str.strip().str.lower()\n",
    "df = df.drop_duplicates(subset='title', keep='first')\n",
    "print(\"Final shape after duplicate removal:\", df.shape)\n",
    "df.to_csv(\"netflix_cleaned_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV with the new column\n",
    "df.to_csv(\"netflix_cleaned_with_year.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
